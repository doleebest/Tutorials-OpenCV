{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "bright = cv2.imread('cube1.jpg')\n",
    "dark = cv2.imread('cube8.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observation : significant perceptual non-uniformity\n",
    "#mixing of chrominance (color related information) and luminance (intensity related information) data\n",
    "\n",
    "#Lab color-space\n",
    "#L-lightness(intensity) ; independent of color info and encodes brightness only\n",
    "#a-color component ranging from green to magenta ; encode color\n",
    "#b-color component ranging from blue to yellow ; encode color\n",
    "\n",
    "# it has the following properties\n",
    "# perceptually uniform color space which approximates how we perceive color\n",
    "# Independent of device ( capturing or displaying)\n",
    "# Used extensively in Adobe Photoshop\n",
    "# Is related to the RGB color space by a complex transformation equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python\n",
    "brightLAB = cv2.cvtColor(bright, cv2.COLOR_BGR2LAB)\n",
    "darkLAB = cv2.cvtColor(dark, cv2.COLOR_BGR2LAB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observation\n",
    "# Similar observations as LAB can be made for Intensity and color components with regard to Illumination changes.\n",
    "# Perceptual difference between Red and Orange is less even in the outdoor image as compared to LAB.\n",
    "# White has undergone change in all 3 components.\n",
    "\n",
    "#HSV color space\n",
    "# H – Hue ( Dominant Wavelength ).\n",
    "# S – Saturation ( Purity / shades of the color ).\n",
    "# V – Value ( Intensity ).\n",
    "\n",
    "# Best thing is that it uses only one channel to describe color (H), making it very intuitive to specify color.\n",
    "# Device dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thr YCrCb Color - space derived from the RGB color space and has the following three components\n",
    "# Y – Luminance or Luma component obtained from RGB after gamma correction.\n",
    "# Cr = R – Y ( how far is the red component from Luma ).\n",
    "# Cb = B – Y ( how far is the blue component from Luma ).\n",
    "\n",
    "# Separates the luminance and chrominance components into different channels.\n",
    "# Mostly used in compression ( of Cr and Cb components ) for TV Transmission.\n",
    "# Device dependent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python\n",
    "brightYCB = cv2.cvtColor(bright, cv2.COLOR_BGR2YCrCb)\n",
    "darkYCB = cv2.cvtColor(dark, cv2.COLOR_BGR2YCrCb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightHSV = cv2.cvtColor(bright, cv2.COLOR_BGR2HSV)\n",
    "darkHSV = cv2.cvtColor(dark, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation\n",
    "# The H Component is very similar in both the images which indicates the color information is intact even under illumination changes.\n",
    "# The S component is also very similar in both images.\n",
    "# The V Component captures the amount of light falling on it thus it changes due to illumination changes.\n",
    "# There is drastic difference between the values of the red piece of outdoor and Indoor image. This is because Hue is represented as a circle and red is at the starting angle. So, it may take values between [300, 360] and again [0, 60]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to use these color spaces for segmentation\n",
    "# the simplest way : lets first try to use them to detect the green color from the cube.\n",
    "\n",
    "#step1 : get the color values for a particular color\n",
    "#step2: applying threshold for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python\n",
    "bgr = [40,158,16]\n",
    "thresh = 40\n",
    "\n",
    "# adjusting the color by subtract thresh from bgr which means the color value of one pixel\n",
    "minBGR = np.array([bgr[0]-thresh, bgr[1]-thresh, bgr[2]-thresh])\n",
    "maxBGR = np.array([bgr[0]-thresh, bgr[1]-thresh, bgr[2]-thresh])\n",
    "\n",
    "maskBGR = cv2.inRange(bright, minBGR, maxBGR) # inRange for finding mask of green pixel\n",
    "resultBGR = cv2.bitwise_and(bright, bright, mask = maskBGR) #maskBGR : 특정 이미지 표시, bright 부분만!\n",
    "#bitwise_and : to get the green pixels from the image using the mask\n",
    "\n",
    "#for converting one pixel to another color space, we first need to convert 1D array to a 3D array\n",
    "#Convert 1D array to 3D, then convert it to HSV and take the first element\n",
    "# this will be same as shown in the above figure [65,229,158]\n",
    "hsv = cv2.cvtColor( np.uint8([[bgr]] ), cv2.COLOR_BGR2HSV)[0][0]#bgr값을 numpy 배열로 변환 -> hsv\n",
    "\n",
    "minHSV = np.array([hsv[0]-thresh, hsv[1]-thresh, hsv[2]-thresh])\n",
    "maxHSV = np.array([hsv[0]+thresh, hsv[1]+thresh, hsv[2]+thresh])\n",
    "\n",
    "maskHSV = cv2.inRange(brightHSV, minHSV, maxHSV) # mask : pick certain area\n",
    "#inRange function is to mask image!\n",
    "resultHSV = cv2.bitwise_and(brightHSV, brightHSV, mask=maskHSV)\n",
    "\n",
    "#convert 1D array to 3D, then convert it to YCrCb and take the first element\n",
    "ycb = cv2.cvtColor( np.uint8([[bgr]] ), cv2.COLOR_BGR2YCrCb)[0][0]\n",
    " \n",
    "minYCB = np.array([ycb[0] - thresh, ycb[1] - thresh, ycb[2] - thresh])\n",
    "maxYCB = np.array([ycb[0] + thresh, ycb[1] + thresh, ycb[2] + thresh])\n",
    " \n",
    "maskYCB = cv2.inRange(brightYCB, minYCB, maxYCB)\n",
    "resultYCB = cv2.bitwise_and(brightYCB, brightYCB, mask = maskYCB)\n",
    "\n",
    "#convert 1D array to 3D, then convert it to LAB and tke the first element\n",
    "lab = cv2.cvtColor( np.uint8([[bgr]] ), cv2.COLOR_BGR2LAB)[0][0]\n",
    "\n",
    "minLAB = np.array([lab[0] - thresh, lab[1] - thresh, lab[2] - thresh])\n",
    "maxLAB = np.array([lab[0] + thresh, lab[1] + thresh, lab[2] + thresh])\n",
    "\n",
    "maskLAB = cv2.inRange(brightLAB, minLAB, maxLAB)\n",
    "resultLAB = cv2.bitwise_and(brightLAB, brightLAB, mask = maskLAB)\n",
    " \n",
    "cv2.imshow(\"Result BGR\", resultBGR)\n",
    "cv2.imshow(\"Result HSV\", resultHSV)\n",
    "cv2.imshow(\"Result YCB\", resultYCB)\n",
    "cv2.imshow(\"Output LAB\", resultLAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m G \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m      8\u001b[0m R \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m----> 9\u001b[0m im \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[43mfi\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#seperate the channels and create and array for each channel by appending the values from each image\u001b[39;00m\n\u001b[1;32m     12\u001b[0m b \u001b[38;5;241m=\u001b[39m im[:,:,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#모든 행, 열 선택 후 세 번째 차원에서 첫번째 채널만 선택하여 추출된 배열 또는 이미지 / 0번째 채널 = 파란색 채널\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fi' is not defined"
     ]
    }
   ],
   "source": [
    "# Same data analysis for a better solution\n",
    "# step 1 : data collection\n",
    "# step 2 ; compute the density plot\n",
    "\n",
    "#we will first load all images of blue or yellow pieces\n",
    "B = np.array([])\n",
    "G = np.array([])\n",
    "R = np.array([])\n",
    "im = cv2.imread(fi)\n",
    "\n",
    "#seperate the channels and create and array for each channel by appending the values from each image\n",
    "b = im[:,:,0] #모든 행, 열 선택 후 세 번째 차원에서 첫번째 채널만 선택하여 추출된 배열 또는 이미지 / 0번째 채널 = 파란색 채널\n",
    "b = b.reshape(b.shape[0]*b.shape[1]) # 이미지의 높이(행) * 이미지의 너비(열) = 이미지의 전체 픽셀 수\n",
    "g = im[:,:,1]\n",
    "g = g.reshape(g.shape[0]*g.shape[1])\n",
    "r = im[:,:,2]\n",
    "r = r.reshape(r.shape[0]*r.shape[1])\n",
    "B = np.append(B,b)\n",
    "G = np.append(G,g)\n",
    "R = np.append(R,r)\n",
    "\n",
    "#use histogram plot from matplotlib to plot the 2D histogram\n",
    "nbins = 10\n",
    "plt.hist2d(B,G,bins=nbins, norm=LogNorm())\n",
    "plt.xlabel('B')\n",
    "plt.ylabel('G')\n",
    "plt.xlim([0,255])\n",
    "plt.ylim([0,255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ideally, we want to work with a color space with the most compact / concentrated density plot for color channels.\n",
    "#The density plots for RGB blow up drastically. This means that the variation in the values of the channels is very high and fixing a threshold is a big problem. Fixing a higher range will detect colors which are similar to the desired color ( False Positives ) and lower range will not detect the desired color in different lighting ( False Negatives ).\n",
    "#In HSV, since only the H component contains information about the absolute color. Thus, it becomes my first choice of color space since I can tweak just one knob ( H ) to specify a color as compared to 2 knobs in YCrCb ( Cr and Cb ) and LAB ( A and B ).\n",
    "#Comparing the plots of YCrCb and LAB shows a higher level of compactness in case of LAB. So, next best choice for me becomes the LAB color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenCV-master-py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
